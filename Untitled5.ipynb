{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPhY56RsltelRxK8fJcwMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b03bf166b8184d2aab823470f86222c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92d03b07661b4c9fbad2fdef220405b6",
              "IPY_MODEL_d0f9a89a174746d6a55b40e03a570257",
              "IPY_MODEL_c84d89f5331c45058c0902a9238f498d"
            ],
            "layout": "IPY_MODEL_7d76a034832f45bb8d5b0f8ff7e17041"
          }
        },
        "92d03b07661b4c9fbad2fdef220405b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0453cf0dee43aa964cd2f5aa3d432b",
            "placeholder": "​",
            "style": "IPY_MODEL_fbfe9907180645e9ad578726bed3544e",
            "value": "Dl Completed...:  80%"
          }
        },
        "d0f9a89a174746d6a55b40e03a570257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4de02b51d0084363b4da853f16d29ac6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10fc7fb5319e4dba85e63d7e8b0977c3",
            "value": 1
          }
        },
        "c84d89f5331c45058c0902a9238f498d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa547a9a79c49268a959c48fed25ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_000d66b5b40648f79bccb4bf938c8d4b",
            "value": " 4/5 [05:26&lt;01:16, 76.11s/ url]"
          }
        },
        "7d76a034832f45bb8d5b0f8ff7e17041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0453cf0dee43aa964cd2f5aa3d432b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfe9907180645e9ad578726bed3544e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4de02b51d0084363b4da853f16d29ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "10fc7fb5319e4dba85e63d7e8b0977c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fa547a9a79c49268a959c48fed25ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000d66b5b40648f79bccb4bf938c8d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e131db266bc4b31ba8625a0ec6ad915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92e0948dc3dd4189ab240af169788aa4",
              "IPY_MODEL_c31afee5a32340168af7fdf6b9082c25",
              "IPY_MODEL_20d0a66398134cbfb7c0fe7bf0ca6bb2"
            ],
            "layout": "IPY_MODEL_55c96d244e2e4840813b01d59dc1ec87"
          }
        },
        "92e0948dc3dd4189ab240af169788aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af837e7f0294b0dabc11487d17fb0de",
            "placeholder": "​",
            "style": "IPY_MODEL_31d7cacb8da44b0e8736c006ecb913ce",
            "value": "Dl Size...:  64%"
          }
        },
        "c31afee5a32340168af7fdf6b9082c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0ea433390d342b8988b0891c83ad5ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38e0652400264b428caa9b9e1f108b15",
            "value": 1
          }
        },
        "20d0a66398134cbfb7c0fe7bf0ca6bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_507d2b97d30440e9a2966b1bc22d0236",
            "placeholder": "​",
            "style": "IPY_MODEL_ee82e094609e408ea1c8341b89b595ee",
            "value": " 16613/25799 [05:26&lt;06:27, 23.68 MiB/s]"
          }
        },
        "55c96d244e2e4840813b01d59dc1ec87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af837e7f0294b0dabc11487d17fb0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d7cacb8da44b0e8736c006ecb913ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0ea433390d342b8988b0891c83ad5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "38e0652400264b428caa9b9e1f108b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "507d2b97d30440e9a2966b1bc22d0236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee82e094609e408ea1c8341b89b595ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1cd2bb1f5a459d883108fdf62c3318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35d217d91b9844f29824330ababf07cf",
              "IPY_MODEL_c50174f63899472e9d5c54fa00c4f406",
              "IPY_MODEL_b498fd3808134663b903829e82fe67ea"
            ],
            "layout": "IPY_MODEL_3b949e1f95ae49fcbbe3304c1587341e"
          }
        },
        "35d217d91b9844f29824330ababf07cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e86f705a20c48a49efbfd2501545826",
            "placeholder": "​",
            "style": "IPY_MODEL_22ed65393a1145d89ee05477591575b2",
            "value": "Extraction completed...:  14%"
          }
        },
        "c50174f63899472e9d5c54fa00c4f406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0ac0c22a6e4ec7b4e2e376fe27d45b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_365962c0eb564649baf4c145e131fafc",
            "value": 1
          }
        },
        "b498fd3808134663b903829e82fe67ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b57f76e33d54259bede2db62dece911",
            "placeholder": "​",
            "style": "IPY_MODEL_61770c98f26548e4954adc1e4081158d",
            "value": " 5008/35241 [05:26&lt;00:59, 506.38 file/s]"
          }
        },
        "3b949e1f95ae49fcbbe3304c1587341e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e86f705a20c48a49efbfd2501545826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ed65393a1145d89ee05477591575b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f0ac0c22a6e4ec7b4e2e376fe27d45b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "365962c0eb564649baf4c145e131fafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b57f76e33d54259bede2db62dece911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61770c98f26548e4954adc1e4081158d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enotnum/halva/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RWUCozzRfdn",
        "outputId": "8445bf84-be36-4b98-fd85-87fe80d95595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U-oNKGVjUYdN",
        "outputId": "fcb153c1-3231-4e03-d1d4-a8e7a6299304"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.8.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.16.0)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.0)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.version.VERSION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TG4BeTIsUYfm",
        "outputId": "1d5c61be-d47a-404b-d202-9cf008370061"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "EORL70KBUYiL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://github.com/srihari-humbarwadi/datasets/releases/download/v0.1.0/data.zip\"#откуда скачивать датасет\n",
        "filename = os.path.join(os.getcwd(), \"data.zip\")#погдготовка переменной с именем архива датасета, который будем скачивать\n",
        "keras.utils.get_file(filename, url)#скачивание архива датасета\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"data.zip\", \"r\") as z_fp:#распаковка скаченного архива\n",
        "    z_fp.extractall(\"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INZxN30kUYki",
        "outputId": "5feccd8d-de9a-483c-83c3-181b7289d306"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/srihari-humbarwadi/datasets/releases/download/v0.1.0/data.zip\n",
            "560525318/560525318 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print (filename)"
      ],
      "metadata": {
        "id": "D03cUaNNUYnI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print (os.getcwd())"
      ],
      "metadata": {
        "id": "UVSHvE4xUYpa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def swap_xy(boxes):\n",
        "    \"\"\"Обмен порядком координат x и y ящиков.\n",
        "\n",
        "    Аргументы:\n",
        "       коробки: тензор с формой `(num_boxes, 4)`, представляющий ограничивающие рамки.\n",
        "\n",
        "     Возвращает:\n",
        "       поменялись местами коробки с формой такой же, как у коробок.\n",
        "     \"\"\"\n",
        "\n",
        "    return tf.stack([boxes[:, 1], boxes[:, 0], boxes[:, 3], boxes[:, 2]], axis=-1)\n",
        "\n",
        "\n",
        "def convert_to_xywh(boxes):\n",
        "    \"\"\"Изменяет формат поля на центр, ширину и высоту.\n",
        "\n",
        "     Аргументы:\n",
        "       коробки: тензор ранга 2 или выше в форме `(..., num_boxes, 4)`\n",
        "         представление ограничивающих рамок, где каждая рамка имеет формат\n",
        "         `[xmin, ymin, xmax, ymax]`.\n",
        "\n",
        "     Возвращает:\n",
        "       преобразованные коробки с формой, такой же, как у коробок.\n",
        "     \"\"\"\n",
        "    return tf.concat(\n",
        "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
        "        axis=-1,\n",
        "    )\n",
        "\n",
        "\n",
        "def convert_to_corners(boxes):\n",
        "\n",
        "    \"\"\"Изменяет формат поля на угловые координаты\n",
        "\n",
        "     Аргументы:\n",
        "       коробки: тензор ранга 2 или выше в форме `(..., num_boxes, 4)`\n",
        "         представление ограничивающих рамок, где каждая рамка имеет формат\n",
        "         `[х, у, ширина, высота]`.\n",
        "\n",
        "     Возвращает:\n",
        "       преобразованные коробки с формой, такой же, как у коробок.\n",
        "     \"\"\"\n",
        "    return tf.concat(\n",
        "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
        "        axis=-1,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "C6cev80yUYrr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bbox = tf.stack(\n",
        "        [\n",
        "          #  [10.0],\n",
        "          #  [0.0],\n",
        "          #  [0.0],\n",
        "          #  [10.0],\n",
        "          [0.0,10.0],\n",
        "           [10.0,10.0],\n",
        "           [10.0,0.0],\n",
        "           [0.0,0.0],\n",
        "        ],\n",
        "        axis=-1,\n",
        "    )\n",
        "print(convert_to_xywh(bbox))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbSBnC9lUYuW",
        "outputId": "f4054481-10a6-4515-f815-4a20bb1179af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  5.   5.  10. -10.]\n",
            " [  5.   5. -10. -10.]], shape=(2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(convert_to_corners(bbox))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpACykqhUYxy",
        "outputId": "be699baa-608b-495e-c183-2eb3595d59cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-5. 10.  5. 10.]\n",
            " [10. 10. 10. 10.]], shape=(2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(swap_xy(bbox))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgRH9C9DXKSd",
        "outputId": "a3563981-7f38-4cf1-ee10-fe37aec552d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10.  0.  0. 10.]\n",
            " [10. 10.  0.  0.]], shape=(2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(boxes1, boxes2):\n",
        "    \"\"\"Вычисляет попарную матрицу IOU для заданных двух наборов коробок\n",
        "\n",
        "     Аргументы:\n",
        "       box1: тензор формы `(N, 4)`, представляющий ограничивающие рамки.\n",
        "         где каждое поле имеет формат `[x, y, ширина, высота]`.\n",
        "         box2: тензор формы `(M, 4)`, представляющий ограничивающие рамки.\n",
        "         где каждое поле имеет формат `[x, y, ширина, высота]`.\n",
        "\n",
        "     Возвращает:\n",
        "       попарная матрица IOU формы `(N, M)`, где значение в i-й строке\n",
        "         j-й столбец содержит долговую расписку между i-м ящиком и j-м ящиком из\n",
        "         ящики1 и ящики2 соответственно.\n",
        "     \"\"\"\n",
        "    boxes1_corners = convert_to_corners(boxes1)\n",
        "    boxes2_corners = convert_to_corners(boxes2)\n",
        "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
        "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
        "    intersection = tf.maximum(0.0, rd - lu)\n",
        "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
        "    boxes1_area = boxes1[:, 2] * boxes1[:, 3]\n",
        "    boxes2_area = boxes2[:, 2] * boxes2[:, 3]\n",
        "    union_area = tf.maximum(\n",
        "        boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8\n",
        "    )\n",
        "    return tf.clip_by_value(intersection_area / union_area, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def visualize_detections(\n",
        "    image, boxes, classes, scores, figsize=(7, 7), linewidth=1, color=[0, 0, 1]\n",
        "):\n",
        "    \"\"\"Visualize Detections\"\"\"\n",
        "    image = np.array(image, dtype=np.uint8)\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image)\n",
        "    ax = plt.gca()\n",
        "    for box, _cls, score in zip(boxes, classes, scores):\n",
        "        text = \"{}: {:.2f}\".format(_cls, score)\n",
        "        x1, y1, x2, y2 = box\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        patch = plt.Rectangle(\n",
        "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth\n",
        "        )\n",
        "        ax.add_patch(patch)\n",
        "        ax.text(\n",
        "            x1,\n",
        "            y1,\n",
        "            text,\n",
        "            bbox={\"facecolor\": color, \"alpha\": 0.4},\n",
        "            clip_box=ax.clipbox,\n",
        "            clip_on=True,\n",
        "        )\n",
        "    plt.show()\n",
        "    return ax\n"
      ],
      "metadata": {
        "id": "GASD7JnsXKVF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnchorBox:\n",
        "    \"\"\"Создает блоки привязки.\n",
        "\n",
        "     Этот класс имеет операции для создания блоков привязки для карт объектов в\n",
        "     шаги `[8, 16, 32, 64, 128]`. Где каждый якорь, каждая коробка\n",
        "     формат `[x, y, ширина, высота]`.\n",
        "\n",
        "     Атрибуты:\n",
        "       аспект_ратиос: список значений с плавающей запятой, представляющих соотношение сторон\n",
        "         якорные поля в каждом месте на карте объектов\n",
        "       Scales: список значений с плавающей запятой, представляющих масштаб полей привязки.\n",
        "         в каждом месте на карте объектов.\n",
        "       num_anchors: количество якорей в каждом месте на карте объектов.\n",
        "       области: список значений с плавающей запятой, представляющих области якоря.\n",
        "         поля для каждой карты объектов в пирамиде объектов.\n",
        "       шаги: список значений с плавающей запятой, представляющих шаги для каждой функции.\n",
        "         карту в пирамиде признаков.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.aspect_ratios = [0.5, 1.0, 2.0]\n",
        "        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\n",
        "\n",
        "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
        "        self._strides = [2 ** i for i in range(3, 8)]\n",
        "        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\n",
        "        self._anchor_dims = self._compute_dims()\n",
        "\n",
        "    def _compute_dims(self):\n",
        "        \"\"\"Вычисляет размеры блока привязки для всех соотношений и масштабов на всех уровнях\n",
        "         пирамиды признаков.\n",
        "        \"\"\"\n",
        "        anchor_dims_all = []\n",
        "        for area in self._areas:\n",
        "            anchor_dims = []\n",
        "            for ratio in self.aspect_ratios:\n",
        "                anchor_height = tf.math.sqrt(area / ratio)\n",
        "                anchor_width = area / anchor_height\n",
        "                dims = tf.reshape(\n",
        "                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\n",
        "                )\n",
        "                for scale in self.scales:\n",
        "                    anchor_dims.append(scale * dims)\n",
        "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
        "        return anchor_dims_all\n",
        "\n",
        "    def _get_anchors(self, feature_height, feature_width, level):\n",
        "        \"\"\"Создает поля привязки для заданного размера и уровня карты объектов\n",
        "\n",
        "         Аргументы:\n",
        "           feature_height: целое число, представляющее высоту карты объектов.\n",
        "           feature_width: целое число, представляющее ширину карты объектов.\n",
        "           level: целое число, представляющее уровень карты объектов в\n",
        "             особенность пирамиды.\n",
        "\n",
        "         Возвращает:\n",
        "           анкерные коробки с формой\n",
        "           `(feature_height * feature_width * num_anchors, 4)`\n",
        "        \"\"\"\n",
        "        rx = tf.range(feature_width, dtype=tf.float32) + 0.5\n",
        "        ry = tf.range(feature_height, dtype=tf.float32) + 0.5\n",
        "        centers = tf.stack(tf.meshgrid(rx, ry), axis=-1) * self._strides[level - 3]\n",
        "        centers = tf.expand_dims(centers, axis=-2)\n",
        "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
        "        dims = tf.tile(\n",
        "            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\n",
        "        )\n",
        "        anchors = tf.concat([centers, dims], axis=-1)\n",
        "        return tf.reshape(\n",
        "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
        "        )\n",
        "\n",
        "    def get_anchors(self, image_height, image_width):\n",
        "        \"\"\"Создает поля привязки для всех карт объектов пирамиды объектов.\n",
        "\n",
        "         Аргументы:\n",
        "           image_height: высота входного изображения.\n",
        "           image_width: ширина входного изображения.\n",
        "\n",
        "         Возвращает:\n",
        "           якорные блоки для всех карт объектов, сложенные в виде единого тензора\n",
        "             с формой `(total_anchors, 4)`\n",
        "        \"\"\"\n",
        "        anchors = [\n",
        "            self._get_anchors(\n",
        "                tf.math.ceil(image_height / 2 ** i),\n",
        "                tf.math.ceil(image_width / 2 ** i),\n",
        "                i,\n",
        "            )\n",
        "            for i in range(3, 8)\n",
        "        ]\n",
        "        return tf.concat(anchors, axis=0)\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "LXp7hfs_XKX6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_flip_horizontal(image, boxes):\n",
        "    \"\"\"Переворачивает изображение и прямоугольники по горизонтали с вероятностью 50%\n",
        "\n",
        "     Аргументы:\n",
        "       изображение: Трехмерный тензор формы `(высота, ширина, каналы)`, представляющий\n",
        "         изображение.\n",
        "       коробки: тензор с формой `(num_boxes, 4)`, представляющий ограничивающие рамки,\n",
        "         имеющие нормированные координаты.\n",
        "\n",
        "     Возвращает:\n",
        "       Случайно перевернутое изображение и коробки\n",
        "     \"\"\"\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        boxes = tf.stack(\n",
        "            [1 - boxes[:, 2], boxes[:, 1], 1 - boxes[:, 0], boxes[:, 3]], axis=-1\n",
        "        )\n",
        "    return image, boxes\n",
        "\n",
        "\n",
        "def resize_and_pad_image(\n",
        "    image, min_side=800.0, max_side=1333.0, jitter=[640, 1024], stride=128.0\n",
        "):\n",
        "    \"\"\"Изменяет размер и дополняет изображение с сохранением соотношения сторон.\n",
        "\n",
        "     1. Изменяет размеры изображений так, чтобы более короткая сторона была равна `min_side`\n",
        "     2. Если длинная сторона больше max_side, измените размер изображения.\n",
        "       с более длинной стороной, равной `max_side`\n",
        "     3. Дополните нулями справа и снизу, чтобы форма изображения делилась на\n",
        "     `шаг`\n",
        "\n",
        "     Аргументы:\n",
        "       изображение: Трехмерный тензор формы `(высота, ширина, каналы)`, представляющий\n",
        "         изображение.\n",
        "       min_side: размер более короткой стороны изображения изменяется до этого значения, если\n",
        "         «дрожание» установлено на «Нет».\n",
        "       max_side: если более длинная сторона изображения превышает это значение после\n",
        "         изменение размера, размер изображения изменяется таким образом, что длинная сторона теперь равна\n",
        "         это значение.\n",
        "       дрожание: список с плавающей запятой, содержащий минимальный и максимальный размер для масштаба\n",
        "         дрожь. Если доступно, более короткая сторона изображения будет\n",
        "         изменяется на случайное значение в этом диапазоне.\n",
        "       шаг: шаг наименьшей карты объектов в пирамиде объектов.\n",
        "         Можно рассчитать с помощью `image_size/feature_map_size`.\n",
        "\n",
        "     Возвращает:\n",
        "       изображение: изображение изменено и дополнено.\n",
        "       image_shape: Форма изображения до заполнения.\n",
        "       ratio: Коэффициент масштабирования, используемый для изменения размера изображения.\n",
        "    \"\"\"\n",
        "    \n",
        "    image_shape = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
        "    if jitter is not None:\n",
        "        min_side = tf.random.uniform((), jitter[0], jitter[1], dtype=tf.float32)\n",
        "    ratio = min_side / tf.reduce_min(image_shape)\n",
        "    if ratio * tf.reduce_max(image_shape) > max_side:\n",
        "        ratio = max_side / tf.reduce_max(image_shape)\n",
        "    image_shape = ratio * image_shape\n",
        "    image = tf.image.resize(image, tf.cast(image_shape, dtype=tf.int32))\n",
        "    padded_image_shape = tf.cast(\n",
        "        tf.math.ceil(image_shape / stride) * stride, dtype=tf.int32\n",
        "    )\n",
        "    image = tf.image.pad_to_bounding_box(\n",
        "        image, 0, 0, padded_image_shape[0], padded_image_shape[1]\n",
        "    )\n",
        "    return image, image_shape, ratio\n",
        "\n",
        "\n",
        "def preprocess_data(sample):\n",
        "    \"\"\"Применяет этап предварительной обработки к одному образцу\n",
        "\n",
        "     Аргументы:\n",
        "       образец: словарь, представляющий одну обучающую выборку.\n",
        "\n",
        "     Возвращает:\n",
        "       изображение: измененный размер и дополненное изображение с примененным случайным горизонтальным отражением.\n",
        "       bbox: ограничивающие рамки формы `(num_objects, 4)`, где каждая рамка\n",
        "         формата `[x, y, ширина, высота]`.\n",
        "       class_id: тензор, представляющий идентификатор класса объектов, имеющий\n",
        "         форма `(num_objects,)`.\n",
        "    \"\"\"\n",
        "    image = sample[\"image\"]\n",
        "    bbox = swap_xy(sample[\"objects\"][\"bbox\"])\n",
        "    class_id = tf.cast(sample[\"objects\"][\"label\"], dtype=tf.int32)\n",
        "\n",
        "    image, bbox = random_flip_horizontal(image, bbox)\n",
        "    image, image_shape, _ = resize_and_pad_image(image)\n",
        "\n",
        "    bbox = tf.stack(\n",
        "        [\n",
        "            bbox[:, 0] * image_shape[1],\n",
        "            bbox[:, 1] * image_shape[0],\n",
        "            bbox[:, 2] * image_shape[1],\n",
        "            bbox[:, 3] * image_shape[0],\n",
        "        ],\n",
        "        axis=-1,\n",
        "    )\n",
        "    bbox = convert_to_xywh(bbox)\n",
        "    return image, bbox, class_id\n"
      ],
      "metadata": {
        "id": "PL22A6JoXKaV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelEncoder:\n",
        "    \"\"\"Преобразует необработанные метки в цели для обучения.\n",
        "\n",
        "     Этот класс имеет операции для создания целей для партии образцов, которые\n",
        "     состоит из входных изображений, ограничивающих рамок для присутствующих объектов и\n",
        "     их идентификаторы классов.\n",
        "\n",
        "     Атрибуты:\n",
        "       anchor_box: Генератор якорных рамок для кодирования ограничивающих рамок.\n",
        "       box_variance: коэффициенты масштабирования, используемые для масштабирования целей ограничительной рамки.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._anchor_box = AnchorBox()\n",
        "        self._box_variance = tf.convert_to_tensor(\n",
        "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def _match_anchor_boxes(\n",
        "        self, anchor_boxes, gt_boxes, match_iou=0.5, ignore_iou=0.4\n",
        "    ):\n",
        "        \"\"\"Сопоставляет блоки наземной истины с блоками привязки на основе долговой расписки.\n",
        "\n",
        "         1. Вычисляет парные IOU для M `anchor_boxes` и N `gt_boxes`\n",
        "           чтобы получить матрицу в форме `(M, N)`.\n",
        "         2. Наземный блок правды с максимальным IOU в каждой строке назначается\n",
        "           поле привязки при условии, что долговая расписка больше, чем `match_iou`.\n",
        "         3. Если максимальное IOU в строке меньше, чем `ignore_iou`, якорь\n",
        "           box назначается фоновым классом.\n",
        "         4. Остальные поля привязки, которым не назначен какой-либо класс,\n",
        "           игнорируются во время обучения.\n",
        "\n",
        "         Аргументы:\n",
        "           anchor_boxes: тензор с плавающей запятой формы `(total_anchors, 4)`\n",
        "             представляющие все поля привязки для заданной формы входного изображения,\n",
        "             где каждое поле привязки имеет формат `[x, y, ширина, высота]`.\n",
        "           gt_boxes: тензор с плавающей запятой формы `(num_objects, 4)`, представляющий\n",
        "             наземные блоки правды, где каждый блок имеет формат\n",
        "             `[х, у, ширина, высота]`.\n",
        "           match_iou: значение с плавающей запятой, представляющее минимальный порог IOU для\n",
        "             определение того, может ли блок истинности основания быть назначен блоку привязки.\n",
        "           ignore_iou: значение с плавающей запятой, представляющее порог IOU, ниже которого\n",
        "             поле привязки назначается фоновому классу.\n",
        "\n",
        "         Возвращает:\n",
        "           matched_gt_idx: индекс совпавшего объекта\n",
        "           Positive_mask: маска для якорных блоков, которым назначена земля.\n",
        "             ящики правды.\n",
        "           ignore_mask: маска для полей привязки, которые необходимо игнорировать во время\n",
        "             обучение\n",
        "        \"\"\"\n",
        "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
        "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
        "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
        "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
        "        negative_mask = tf.less(max_iou, ignore_iou)\n",
        "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
        "        return (\n",
        "            matched_gt_idx,\n",
        "            tf.cast(positive_mask, dtype=tf.float32),\n",
        "            tf.cast(ignore_mask, dtype=tf.float32),\n",
        "        )\n",
        "\n",
        "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
        "        \"\"\"Превращает наземные ящики правды в цели для обучения\"\"\"\n",
        "        box_target = tf.concat(\n",
        "            [\n",
        "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
        "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:]),\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "        box_target = box_target / self._box_variance\n",
        "        return box_target\n",
        "\n",
        "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):\n",
        "        \"\"\"Создает коробки и цели классификации для одного образца\"\"\"\n",
        "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
        "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
        "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
        "            anchor_boxes, gt_boxes\n",
        "        )\n",
        "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
        "        box_target = self._compute_box_target(anchor_boxes, matched_gt_boxes)\n",
        "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
        "        cls_target = tf.where(\n",
        "            tf.not_equal(positive_mask, 1.0), -1.0, matched_gt_cls_ids\n",
        "        )\n",
        "        cls_target = tf.where(tf.equal(ignore_mask, 1.0), -2.0, cls_target)\n",
        "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
        "        label = tf.concat([box_target, cls_target], axis=-1)\n",
        "        return label\n",
        "\n",
        "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
        "        \"\"\"Создает коробки и цели классификации для партии\"\"\"\n",
        "        images_shape = tf.shape(batch_images)\n",
        "        batch_size = images_shape[0]\n",
        "\n",
        "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
        "        for i in range(batch_size):\n",
        "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
        "            labels = labels.write(i, label)\n",
        "        batch_images = tf.keras.applications.resnet.preprocess_input(batch_images)\n",
        "        return batch_images, labels.stack()"
      ],
      "metadata": {
        "id": "IQ3uysqeXKdG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_backbone():\n",
        "    \"\"\"Создает ResNet50 с предварительно обученными весами imagenet\"\"\"\n",
        "    backbone = keras.applications.ResNet50(\n",
        "        include_top=False, input_shape=[None, None, 3]\n",
        "    )\n",
        "    c3_output, c4_output, c5_output = [\n",
        "        backbone.get_layer(layer_name).output\n",
        "        for layer_name in [\"conv3_block4_out\", \"conv4_block6_out\", \"conv5_block3_out\"]\n",
        "    ]\n",
        "    return keras.Model(\n",
        "        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "j-gNKCuuXKfq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeaturePyramid(keras.layers.Layer):\n",
        "    \"\"\"Строит пирамиду функций с картами функций из основы.\n",
        "\n",
        "     Атрибуты:\n",
        "       num_classes: количество классов в наборе данных.\n",
        "       основа: основа для построения пирамиды функций.\n",
        "         В настоящее время поддерживает только ResNet50.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, backbone=None, **kwargs):\n",
        "        super().__init__(name=\"FeaturePyramid\", **kwargs)\n",
        "        self.backbone = backbone if backbone else get_backbone()\n",
        "        self.conv_c3_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c4_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c5_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c3_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c4_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c5_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c6_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
        "        self.conv_c7_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
        "        self.upsample_2x = keras.layers.UpSampling2D(2)\n",
        "\n",
        "    def call(self, images, training=False):\n",
        "        c3_output, c4_output, c5_output = self.backbone(images, training=training)\n",
        "        p3_output = self.conv_c3_1x1(c3_output)\n",
        "        p4_output = self.conv_c4_1x1(c4_output)\n",
        "        p5_output = self.conv_c5_1x1(c5_output)\n",
        "        p4_output = p4_output + self.upsample_2x(p5_output)\n",
        "        p3_output = p3_output + self.upsample_2x(p4_output)\n",
        "        p3_output = self.conv_c3_3x3(p3_output)\n",
        "        p4_output = self.conv_c4_3x3(p4_output)\n",
        "        p5_output = self.conv_c5_3x3(p5_output)\n",
        "        p6_output = self.conv_c6_3x3(c5_output)\n",
        "        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n",
        "        return p3_output, p4_output, p5_output, p6_output, p7_output\n"
      ],
      "metadata": {
        "id": "U3vDcM5Re9Dr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_head(output_filters, bias_init):\n",
        "    \"\"\"Создает заголовок прогнозов класса/блока.\n",
        "\n",
        "     Аргументы:\n",
        "       output_filters: количество сверточных фильтров в последнем слое.\n",
        "       bias_init: Инициализатор смещения для окончательного слоя свертки.\n",
        "\n",
        "     Возвращает:\n",
        "       Последовательная модель keras, представляющая классификацию\n",
        "         или заголовок регрессии блока в зависимости от `output_filters`.\n",
        "    \"\"\"\n",
        "    head = keras.Sequential([keras.Input(shape=[None, None, 256])])\n",
        "    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n",
        "    for _ in range(4):\n",
        "        head.add(\n",
        "            keras.layers.Conv2D(256, 3, padding=\"same\", kernel_initializer=kernel_init)\n",
        "        )\n",
        "        head.add(keras.layers.ReLU())\n",
        "    head.add(\n",
        "        keras.layers.Conv2D(\n",
        "            output_filters,\n",
        "            3,\n",
        "            1,\n",
        "            padding=\"same\",\n",
        "            kernel_initializer=kernel_init,\n",
        "            bias_initializer=bias_init,\n",
        "        )\n",
        "    )\n",
        "    return head"
      ],
      "metadata": {
        "id": "Ne26au3je9GN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RetinaNet(keras.Model):\n",
        "    \"\"\"Подкласс модели Keras, реализующий архитектуру RetinaNet.\n",
        "\n",
        "     Атрибуты:\n",
        "       num_classes: количество классов в наборе данных.\n",
        "       основа: основа для построения пирамиды функций.\n",
        "         В настоящее время поддерживает только ResNet50.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, backbone=None, **kwargs):\n",
        "        super().__init__(name=\"RetinaNet\", **kwargs)\n",
        "        self.fpn = FeaturePyramid(backbone)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
        "        self.cls_head = build_head(9 * num_classes, prior_probability)\n",
        "        self.box_head = build_head(9 * 4, \"zeros\")\n",
        "\n",
        "    def call(self, image, training=False):\n",
        "        features = self.fpn(image, training=training)\n",
        "        N = tf.shape(image)[0]\n",
        "        cls_outputs = []\n",
        "        box_outputs = []\n",
        "        for feature in features:\n",
        "            box_outputs.append(tf.reshape(self.box_head(feature), [N, -1, 4]))\n",
        "            cls_outputs.append(\n",
        "                tf.reshape(self.cls_head(feature), [N, -1, self.num_classes])\n",
        "            )\n",
        "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
        "        box_outputs = tf.concat(box_outputs, axis=1)\n",
        "        return tf.concat([box_outputs, cls_outputs], axis=-1)\n"
      ],
      "metadata": {
        "id": "UsbINWFse9Iw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecodePredictions(tf.keras.layers.Layer):\n",
        "    \"\"\"Слой Keras, который декодирует прогнозы модели RetinaNet.\n",
        "\n",
        "     Атрибуты:\n",
        "       num_classes: количество классов в наборе данных\n",
        "       trust_threshold: минимальная вероятность класса, ниже которой обнаружения\n",
        "         обрезаются.\n",
        "       nms_iou_threshold: порог IOU для операции NMS\n",
        "       max_detections_per_class: максимальное количество обнаружений, которые необходимо сохранить на\n",
        "        сорт.\n",
        "       max_detections: максимальное количество обнаружений для всех\n",
        "         классы.\n",
        "       box_variance: Коэффициенты масштабирования, используемые для масштабирования ограничивающей рамки.\n",
        "         предсказания.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes=80,\n",
        "        confidence_threshold=0.05,\n",
        "        nms_iou_threshold=0.5,\n",
        "        max_detections_per_class=100,\n",
        "        max_detections=100,\n",
        "        box_variance=[0.1, 0.1, 0.2, 0.2],\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "        self.nms_iou_threshold = nms_iou_threshold\n",
        "        self.max_detections_per_class = max_detections_per_class\n",
        "        self.max_detections = max_detections\n",
        "\n",
        "        self._anchor_box = AnchorBox()\n",
        "        self._box_variance = tf.convert_to_tensor(\n",
        "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def _decode_box_predictions(self, anchor_boxes, box_predictions):\n",
        "        boxes = box_predictions * self._box_variance\n",
        "        boxes = tf.concat(\n",
        "            [\n",
        "                boxes[:, :, :2] * anchor_boxes[:, :, 2:] + anchor_boxes[:, :, :2],\n",
        "                tf.math.exp(boxes[:, :, 2:]) * anchor_boxes[:, :, 2:],\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "        boxes_transformed = convert_to_corners(boxes)\n",
        "        return boxes_transformed\n",
        "\n",
        "    def call(self, images, predictions):\n",
        "        image_shape = tf.cast(tf.shape(images), dtype=tf.float32)\n",
        "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
        "        box_predictions = predictions[:, :, :4]\n",
        "        cls_predictions = tf.nn.sigmoid(predictions[:, :, 4:])\n",
        "        boxes = self._decode_box_predictions(anchor_boxes[None, ...], box_predictions)\n",
        "\n",
        "        return tf.image.combined_non_max_suppression(\n",
        "            tf.expand_dims(boxes, axis=2),\n",
        "            cls_predictions,\n",
        "            self.max_detections_per_class,\n",
        "            self.max_detections,\n",
        "            self.nms_iou_threshold,\n",
        "            self.confidence_threshold,\n",
        "            clip_boxes=False,\n",
        "        )"
      ],
      "metadata": {
        "id": "t7pUvl-de9LM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RetinaNetBoxLoss(tf.losses.Loss):\n",
        "    \"\"\"Реализует гладкую потерю L1\"\"\"\n",
        "\n",
        "    def __init__(self, delta):\n",
        "        super().__init__(\n",
        "            reduction=\"none\", name=\"RetinaNetBoxLoss\"\n",
        "        )\n",
        "        self._delta = delta\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        difference = y_true - y_pred\n",
        "        absolute_difference = tf.abs(difference)\n",
        "        squared_difference = difference ** 2\n",
        "        loss = tf.where(\n",
        "            tf.less(absolute_difference, self._delta),\n",
        "            0.5 * squared_difference,\n",
        "            absolute_difference - 0.5,\n",
        "        )\n",
        "        return tf.reduce_sum(loss, axis=-1)\n",
        "\n",
        "\n",
        "class RetinaNetClassificationLoss(tf.losses.Loss):\n",
        "    \"\"\"Реализует очаговую потерю\"\"\"\n",
        "\n",
        "    def __init__(self, alpha, gamma):\n",
        "        super().__init__(\n",
        "            reduction=\"none\", name=\"RetinaNetClassificationLoss\"\n",
        "        )\n",
        "        self._alpha = alpha\n",
        "        self._gamma = gamma\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            labels=y_true, logits=y_pred\n",
        "        )\n",
        "        probs = tf.nn.sigmoid(y_pred)\n",
        "        alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
        "        pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
        "        loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n",
        "        return tf.reduce_sum(loss, axis=-1)\n",
        "\n",
        "\n",
        "class RetinaNetLoss(tf.losses.Loss):\n",
        "    \"\"\"Обертка для объединения обеих потерь\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=80, alpha=0.25, gamma=2.0, delta=1.0):\n",
        "        super().__init__(reduction=\"auto\", name=\"RetinaNetLoss\")\n",
        "        self._clf_loss = RetinaNetClassificationLoss(alpha, gamma)\n",
        "        self._box_loss = RetinaNetBoxLoss(delta)\n",
        "        self._num_classes = num_classes\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        box_labels = y_true[:, :, :4]\n",
        "        box_predictions = y_pred[:, :, :4]\n",
        "        cls_labels = tf.one_hot(\n",
        "            tf.cast(y_true[:, :, 4], dtype=tf.int32),\n",
        "            depth=self._num_classes,\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "        cls_predictions = y_pred[:, :, 4:]\n",
        "        positive_mask = tf.cast(tf.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
        "        ignore_mask = tf.cast(tf.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
        "        clf_loss = self._clf_loss(cls_labels, cls_predictions)\n",
        "        box_loss = self._box_loss(box_labels, box_predictions)\n",
        "        clf_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, clf_loss)\n",
        "        box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
        "        normalizer = tf.reduce_sum(positive_mask, axis=-1)\n",
        "        clf_loss = tf.math.divide_no_nan(tf.reduce_sum(clf_loss, axis=-1), normalizer)\n",
        "        box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
        "        loss = clf_loss + box_loss\n",
        "        return loss"
      ],
      "metadata": {
        "id": "SucurNb6e9Nu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"retinanet/\"\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "num_classes = 80\n",
        "batch_size = 2\n",
        "\n",
        "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
        "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
        "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=learning_rate_boundaries, values=learning_rates\n",
        ")"
      ],
      "metadata": {
        "id": "PSM_zPz9e9QG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_backbone = get_backbone()\n",
        "loss_fn = RetinaNetLoss(num_classes)\n",
        "model = RetinaNet(num_classes, resnet50_backbone)\n",
        "\n",
        "optimizer = tf.optimizers.legacy.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
        "model.compile(loss=loss_fn, optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJbt6Vtte9Sq",
        "outputId": "739b61f4-b870-4035-fda5-201860d4fbbc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
        "        monitor=\"loss\",\n",
        "        save_best_only=False,\n",
        "        save_weights_only=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "Dp4XVoFmXKiS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#может понадобится, на шаге обучения моделyибка\n",
        "! pip uninstall keras\n",
        "! pip uninstall tensorflow\n",
        "\n",
        "! pip install tensorflow\n",
        "! pip install keras\n",
        "#может понадобится, на шаге обучения модели может возникнуть ошибка"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "okj85IrxfWb-",
        "outputId": "0c21c6ff-0265-49da-827f-f05a6b631403"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 2.11.0\n",
            "Uninstalling keras-2.11.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/keras-2.11.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/keras/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled keras-2.11.0\n",
            "Found existing installation: tensorflow 2.11.0\n",
            "Uninstalling tensorflow-2.11.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.11.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Downloading protobuf-4.23.2-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.6.1\n",
            "    Uninstalling tensorboard-data-server-0.6.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "Successfully installed google-auth-oauthlib-1.0.0 keras-2.12.0 protobuf-4.23.2 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набор данных COCO2017, используя наборы данных TensorFlow"
      ],
      "metadata": {
        "id": "Y9Ds98GhfiWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# установите `data_dir=None`, чтобы загрузить полный набор данных\n",
        "\n",
        "(train_dataset, val_dataset), dataset_info = tfds.load(\n",
        "    \"coco/2017\", split=[\"train\", \"validation\"], with_info=True, data_dir=\"None\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b03bf166b8184d2aab823470f86222c1",
            "92d03b07661b4c9fbad2fdef220405b6",
            "d0f9a89a174746d6a55b40e03a570257",
            "c84d89f5331c45058c0902a9238f498d",
            "7d76a034832f45bb8d5b0f8ff7e17041",
            "cb0453cf0dee43aa964cd2f5aa3d432b",
            "fbfe9907180645e9ad578726bed3544e",
            "4de02b51d0084363b4da853f16d29ac6",
            "10fc7fb5319e4dba85e63d7e8b0977c3",
            "3fa547a9a79c49268a959c48fed25ea9",
            "000d66b5b40648f79bccb4bf938c8d4b",
            "6e131db266bc4b31ba8625a0ec6ad915",
            "92e0948dc3dd4189ab240af169788aa4",
            "c31afee5a32340168af7fdf6b9082c25",
            "20d0a66398134cbfb7c0fe7bf0ca6bb2",
            "55c96d244e2e4840813b01d59dc1ec87",
            "4af837e7f0294b0dabc11487d17fb0de",
            "31d7cacb8da44b0e8736c006ecb913ce",
            "e0ea433390d342b8988b0891c83ad5ff",
            "38e0652400264b428caa9b9e1f108b15",
            "507d2b97d30440e9a2966b1bc22d0236",
            "ee82e094609e408ea1c8341b89b595ee",
            "5a1cd2bb1f5a459d883108fdf62c3318",
            "35d217d91b9844f29824330ababf07cf",
            "c50174f63899472e9d5c54fa00c4f406",
            "b498fd3808134663b903829e82fe67ea",
            "3b949e1f95ae49fcbbe3304c1587341e",
            "3e86f705a20c48a49efbfd2501545826",
            "22ed65393a1145d89ee05477591575b2",
            "0f0ac0c22a6e4ec7b4e2e376fe27d45b",
            "365962c0eb564649baf4c145e131fafc",
            "3b57f76e33d54259bede2db62dece911",
            "61770c98f26548e4954adc1e4081158d"
          ]
        },
        "id": "oeACNeiGfWg1",
        "outputId": "83827577-ecde-4f68-8389-ebc7d19ae856"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 25.20 GiB (download: 25.20 GiB, generated: Unknown size, total: 25.20 GiB) to None/coco/2017/1.1.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b03bf166b8184d2aab823470f86222c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e131db266bc4b31ba8625a0ec6ad915"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a1cd2bb1f5a459d883108fdf62c3318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-6f617aa49977>\", line 3, in <cell line: 3>\n",
            "    (train_dataset, val_dataset), dataset_info = tfds.load(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 169, in __call__\n",
            "    return function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\", line 640, in load\n",
            "    _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\", line 499, in _download_and_prepare_builder\n",
            "    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 169, in __call__\n",
            "    return function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 646, in download_and_prepare\n",
            "    self._download_and_prepare(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 1498, in _download_and_prepare\n",
            "    split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/object_detection/coco.py\", line 245, in _split_generators\n",
            "    extracted_paths = dl_manager.download_and_extract(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 687, in download_and_extract\n",
            "    return _map_promise(self._download_extract, url_or_urls)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 830, in _map_promise\n",
            "    res = tree_utils.map_structure(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tree/__init__.py\", line 435, in map_structure\n",
            "    [func(*args) for args in zip(*map(flatten, structures))])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tree/__init__.py\", line 435, in <listcomp>\n",
            "    [func(*args) for args in zip(*map(flatten, structures))])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 831, in <lambda>\n",
            "    lambda p: p.get(), all_promises\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 511, in get\n",
            "    self._wait(timeout or DEFAULT_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 506, in _wait\n",
            "    self.wait(self, timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 502, in wait\n",
            "    async_instance.wait(promise, timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/async_.py\", line 117, in wait\n",
            "    target.scheduler.wait(target, timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/schedulers/immediate.py\", line 25, in wait\n",
            "    waited = e.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 826, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-6f617aa49977>\", line 3, in <cell line: 3>\n",
            "    (train_dataset, val_dataset), dataset_info = tfds.load(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 169, in __call__\n",
            "    return function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\", line 640, in load\n",
            "    _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\", line 499, in _download_and_prepare_builder\n",
            "    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 169, in __call__\n",
            "    return function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 646, in download_and_prepare\n",
            "    self._download_and_prepare(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 1498, in _download_and_prepare\n",
            "    split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/object_detection/coco.py\", line 245, in _split_generators\n",
            "    extracted_paths = dl_manager.download_and_extract(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 687, in download_and_extract\n",
            "    return _map_promise(self._download_extract, url_or_urls)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 830, in _map_promise\n",
            "    res = tree_utils.map_structure(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tree/__init__.py\", line 435, in map_structure\n",
            "    [func(*args) for args in zip(*map(flatten, structures))])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tree/__init__.py\", line 435, in <listcomp>\n",
            "    [func(*args) for args in zip(*map(flatten, structures))])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 831, in <lambda>\n",
            "    lambda p: p.get(), all_promises\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 511, in get\n",
            "    self._wait(timeout or DEFAULT_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 506, in _wait\n",
            "    self.wait(self, timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/promise.py\", line 502, in wait\n",
            "    async_instance.wait(promise, timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/async_.py\", line 117, in wait\n",
            "    target.scheduler.wait(target, timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/promise/schedulers/immediate.py\", line 25, in wait\n",
            "    waited = e.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 431, in _joinrealpath\n",
            "    st = os.lstat(newpath)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6f617aa49977>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m (train_dataset, val_dataset), dataset_info = tfds.load(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"coco/2017\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    639\u001b[0m   )\n\u001b[0;32m--> 640\u001b[0;31m   \u001b[0m_download_and_prepare_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36m_download_and_prepare_builder\u001b[0;34m(dbuilder, download, download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/logging/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m           self._download_and_prepare(\n\u001b[0m\u001b[1;32m    647\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0moptional_pipeline_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m       split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\n\u001b[0m\u001b[1;32m   1499\u001b[0m           \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptional_pipeline_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/object_detection/coco.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mroot_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://images.cocodataset.org/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     extracted_paths = dl_manager.download_and_extract(\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    686\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_map_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_map_promise\u001b[0;34m(map_fn, all_inputs)\u001b[0m\n\u001b[1;32m    829\u001b[0m   )  # Apply the function\n\u001b[0;32m--> 830\u001b[0;31m   res = tree_utils.map_structure(\n\u001b[0m\u001b[1;32m    831\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 435\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    434\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 435\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    830\u001b[0m   res = tree_utils.map_structure(\n\u001b[0;32m--> 831\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m   )  # Wait promises\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/promise/promise.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/promise/promise.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# type: (Optional[float]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/promise/promise.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(cls, promise, timeout)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# type: (Promise, Optional[float]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0masync_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpromise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/promise/async_.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, promise, timeout)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/promise/schedulers/immediate.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, promise, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpromise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_then\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_resolve_or_reject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_resolve_or_reject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mwaited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwaited\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3472\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3473\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3474\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[0m\n\u001b[1;32m   3255\u001b[0m                     \u001b[0minteractivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'async'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0m\u001b[1;32m   3258\u001b[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3491\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3492\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3493\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mchained_exc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0m\u001b[1;32m   1143\u001b[0m                                                                      chained_exceptions_tb_offset)\n\u001b[1;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autotune = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "train_dataset = train_dataset.shuffle(8 * batch_size)\n",
        "train_dataset = train_dataset.padded_batch(\n",
        "    batch_size=batch_size, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
        ")\n",
        "train_dataset = train_dataset.map(\n",
        "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
        ")\n",
        "train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\n",
        "train_dataset = train_dataset.prefetch(autotune)\n",
        "\n",
        "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "val_dataset = val_dataset.padded_batch(\n",
        "    batch_size=1, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
        ")\n",
        "val_dataset = val_dataset.map(label_encoder.encode_batch, num_parallel_calls=autotune)\n",
        "val_dataset = val_dataset.apply(tf.data.experimental.ignore_errors())\n",
        "val_dataset = val_dataset.prefetch(autotune)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "7_mbHApafWjV",
        "outputId": "295aec4f-7aa1-4073-94a1-e82e44ff2354"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-76c3489b2a59>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautotune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautotune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_dataset = train_dataset.padded_batch(\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Раскомментируйте следующие строки при обучении на полном наборе(!) данных.\n",
        "train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples\n",
        "val_steps_per_epoch = \\\n",
        "dataset_info.splits[\"validation\"].num_examples\n",
        "\n",
        "train_steps = 4 * 100000\n",
        "epochs = train_steps // train_steps_per_epoch\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "# Запуск 100 обучающих и 50 шагов проверки,\n",
        "# удалить `.take` при обучении на полном наборе данных\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,#100\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "pWXZkbhhfWnS",
        "outputId": "1ae0e926-7d6e-40a7-c183-9c0cc5d58558"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d25ff08c94c8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Раскомментируйте следующие строки при обучении на полном наборе(!) данных.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_steps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_steps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_info' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Измените это на `model_dir`, если не используете загруженные веса.\n",
        "weights_dir = \"data\"\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
        "model.load_weights(latest_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "uiQ41prdg9oe",
        "outputId": "a2b6f6fe-d53b-4b9d-b50a-87c36b1fa3e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1f911a205aae>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweights_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlatest_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.keras.Input(shape=[None, None, 3], name=\"image\")\n",
        "predictions = model(image, training=False)\n",
        "detections = DecodePredictions(confidence_threshold=0.5)(image, predictions)\n",
        "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
      ],
      "metadata": {
        "id": "ncWKIddBg9rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "rvf8_lThg9uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numPicture = 161"
      ],
      "metadata": {
        "id": "yssg_ahLhSg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(image):\n",
        "    image, _, ratio = resize_and_pad_image(image, jitter=None)\n",
        "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
        "    return tf.expand_dims(image, axis=0), ratio\n",
        "#[161:162]\n",
        "val_dataset = tfds.load(\"coco/2017\", split=\"validation[\"+str(numPicture)+\":\"+str(numPicture+1)+\"]\", data_dir=\"data\")\n",
        "int2str = dataset_info.features[\"objects\"][\"label\"].int2str\n",
        "len(val_dataset)"
      ],
      "metadata": {
        "id": "onyRmCeShSjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in val_dataset.take(1):\n",
        "    image = tf.cast(sample[\"image\"], dtype=tf.float32)\n",
        "    input_image, ratio = prepare_image(image)\n",
        "    detections = inference_model.predict(input_image)\n",
        "    num_detections = detections.valid_detections[0]\n",
        "    class_names = [\n",
        "        int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]\n",
        "    ]\n",
        "    visualize_detections(\n",
        "        image,\n",
        "        detections.nmsed_boxes[0][:num_detections] / ratio,\n",
        "        class_names,\n",
        "        detections.nmsed_scores[0][:num_detections],\n",
        "    )"
      ],
      "metadata": {
        "id": "yYbr-5D7hSmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85UmDMbrhSoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}